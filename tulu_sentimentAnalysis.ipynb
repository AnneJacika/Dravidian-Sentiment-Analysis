{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7BjaWmjbT2zg"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import spacy\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tulu_df=pd.read_csv(\"/content/Tulu_SA_train (1).csv\")\n",
        "tulu_dev=pd.read_csv(\"/content/Tulu_SA_val (1).csv\")\n",
        "tulu_test=pd.read_csv(\"/content/Tulu_SA_test_without_label (1).csv\")"
      ],
      "metadata": {
        "id": "sry3ODacUK4C"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tulu_train=pd.concat([tulu_df, tulu_dev], ignore_index=True)\n",
        "tulu_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3MzimmSGURbH",
        "outputId": "0d805cf2-1b23-4925-8c18-2da113578c34"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                Text     Label\n",
              "0                          Aunty log bohot kadak hai  Not Tulu\n",
              "1  Shruthi was awesome... Nice collaboration... H...  Not Tulu\n",
              "2                  Gol gappadh ammana sajjigene best  Positive\n",
              "3                 Chaddida brand thojodijji marreðŸ˜ƒðŸ˜ƒðŸ˜ƒ   Neutral\n",
              "4                     Memories just got refreshed...  Not Tulu"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e34817ef-3ecf-4500-bee5-93290f185e66\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Aunty log bohot kadak hai</td>\n",
              "      <td>Not Tulu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Shruthi was awesome... Nice collaboration... H...</td>\n",
              "      <td>Not Tulu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Gol gappadh ammana sajjigene best</td>\n",
              "      <td>Positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Chaddida brand thojodijji marreðŸ˜ƒðŸ˜ƒðŸ˜ƒ</td>\n",
              "      <td>Neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Memories just got refreshed...</td>\n",
              "      <td>Not Tulu</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e34817ef-3ecf-4500-bee5-93290f185e66')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e34817ef-3ecf-4500-bee5-93290f185e66 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e34817ef-3ecf-4500-bee5-93290f185e66');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-088b758d-747c-435a-b711-f3af5a8a7d01\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-088b758d-747c-435a-b711-f3af5a8a7d01')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-088b758d-747c-435a-b711-f3af5a8a7d01 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "tulu_train",
              "summary": "{\n  \"name\": \"tulu_train\",\n  \"rows\": 14951,\n  \"fields\": [\n    {\n      \"column\": \"Text\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 14951,\n        \"samples\": [\n          \"Deepak Rai and Shobha rai Is the top performers\",\n          \"Poppankule.. tindre chips tikkuva..???\\ud83d\\ude01\\ud83d\\ude02\",\n          \"Full drama padle plzzz\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Label\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Positive\",\n          \"Negative\",\n          \"Neutral\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cleaning the training dataset"
      ],
      "metadata": {
        "id": "lYaoY8IfUVsV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions\n",
        "#CLEANING THE DEVELOPED TULU\n",
        "tulu_train = tulu_train.dropna(subset=['Label'])\n",
        "import re\n",
        "\n",
        "# Apply the cleaning logic to the \"Text\" column\n",
        "tulu_train[\"Text\"] = tulu_train[\"Text\"].apply(lambda x: re.sub(r'\\s+', ' ', str(x).strip()))\n",
        "\n",
        "# Convert the \"Text\" column to lowercase\n",
        "tulu_train[\"Text\"] = tulu_train[\"Text\"].str.lower()\n",
        "import re\n",
        "import string\n",
        "\n",
        "# Clean, remove punctuation, and convert to lowercase\n",
        "tulu_train[\"Text\"] = tulu_train[\"Text\"].apply(\n",
        "    lambda x: re.sub(r'\\s+', ' ', ''.join(char for char in str(x) if char not in string.punctuation).strip()).lower()\n",
        ")\n",
        "\n",
        "\n",
        "import re\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    # Remove emojis using regex\n",
        "    text = re.sub(r'[^\\w\\s,]', '', text)\n",
        "    # Remove extra whitespace\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()\n",
        "    return text\n",
        "\n",
        "# Apply the cleaning function to the \"Text\" column\n",
        "tulu_train[\"Text\"] = tulu_train[\"Text\"].apply(clean_text)\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download stopwords if not already downloaded\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "# Remove stopwords\n",
        "tulu_train[\"Text\"] = tulu_train[\"Text\"].apply(\n",
        "    lambda x: ' '.join(word for word in x.split() if word not in stop_words)\n",
        ")\n",
        "\n",
        "\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# Download WordNet data if not already downloaded\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "# Lemmatize each word in the text\n",
        "tulu_train[\"Text\"] = tulu_train[\"Text\"].apply(\n",
        "    lambda x: ' '.join(lemmatizer.lemmatize(word) for word in x.split())\n",
        ")\n",
        "\n",
        "import contractions\n",
        "\n",
        "# Expand contractions\n",
        "tulu_train[\"Text\"] = tulu_train[\"Text\"].apply(lambda x: contractions.fix(x))\n",
        "\n",
        "custom_stopwords = {\"super\", \"vlog\", \"gameplay\"}\n",
        "\n",
        "tulu_train[\"Text\"] = tulu_train[\"Text\"].apply(\n",
        "    lambda x: ' '.join(word for word in x.split() if word not in custom_stopwords)\n",
        ")\n",
        "\n",
        "# Replace negations\n",
        "tulu_train[\"Text\"] = tulu_train[\"Text\"].apply(\n",
        "    lambda x: re.sub(r'\\bnot (\\w+)', r'not_\\1', x)\n",
        ")\n",
        "\n",
        "# Remove repeated characters\n",
        "tulu_train[\"Text\"] = tulu_train[\"Text\"].apply(\n",
        "    lambda x: re.sub(r'(.)\\1+', r'\\1\\1', x)\n",
        ")\n",
        "\n",
        "# Remove non-ASCII characters\n",
        "tulu_train[\"Text\"] = tulu_train[\"Text\"].apply(lambda x: x.encode('ascii', 'ignore').decode('utf-8'))\n",
        "\n",
        "tulu_train = tulu_train.dropna(subset=['Text'])\n",
        "tulu_train = tulu_train.dropna(subset=['Text'])\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Define stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)  # Remove non-alphabetic characters\n",
        "    text = \" \".join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
        "    return text\n",
        "\n",
        "# Apply cleaning function to the 'Text' column\n",
        "tulu_train['cleaned_text'] = tulu_train['Text'].apply(clean_text)\n",
        "\n",
        "tulu_train[tulu_train['cleaned_text'].str.strip() == '']  # Find rows with empty cleaned_text\n",
        "\n",
        "# Drop rows with empty 'cleaned_text'\n",
        "tulu_train = tulu_train[tulu_train['cleaned_text'].str.strip() != '']  # Remove rows where cleaned_text is empty\n",
        "\n",
        "import re\n",
        "\n",
        "# Function to remove repeating characters from any word\n",
        "def remove_repeated_chars(text):\n",
        "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
        "\n",
        "# Apply function to remove repeated characters in the entire column\n",
        "tulu_train['cleaned_text'] = tulu_train['cleaned_text'].apply(remove_repeated_chars)\n",
        "\n",
        "# Verify the column has been created\n",
        "print(tulu_train.head())  # Check the first few rows to confirm the new column\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3hL38g-DUY5w",
        "outputId": "2aedcb33-db3f-4570-8235-7bc1bda3998d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.11/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.11/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-bfff1a99b97e>:7: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tulu_train[\"Text\"] = tulu_train[\"Text\"].apply(lambda x: re.sub(r'\\s+', ' ', str(x).strip()))\n",
            "<ipython-input-9-bfff1a99b97e>:10: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tulu_train[\"Text\"] = tulu_train[\"Text\"].str.lower()\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                Text     Label  \\\n",
            "0                          aunty log bohot kadak hai  Not Tulu   \n",
            "1  shruthi awesome nice collaboration hope see yo...  Not Tulu   \n",
            "2                  gol gappadh ammana sajjigene best  Positive   \n",
            "3                    chaddida brand thojodijji marre   Neutral   \n",
            "4                               memory got refreshed  Not Tulu   \n",
            "\n",
            "                                        cleaned_text  \n",
            "0                          aunty log bohot kadak hai  \n",
            "1  shruthi awesome nice colaboration hope se upco...  \n",
            "2                     gol gapadh amana sajigene best  \n",
            "3                       chadida brand thojodiji mare  \n",
            "4                               memory got refreshed  \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "<ipython-input-9-bfff1a99b97e>:118: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  tulu_train['cleaned_text'] = tulu_train['cleaned_text'].apply(remove_repeated_chars)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Cleaning Testing dataset"
      ],
      "metadata": {
        "id": "QmITa8AGUfN7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install contractions\n",
        "\n",
        "import re\n",
        "import string\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import contractions\n",
        "import nltk\n",
        "\n",
        "# Download necessary data\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')\n",
        "\n",
        "\n",
        "# Initial preprocessing: clean and normalize text\n",
        "tulu_test[\"Text\"] = tulu_test[\"Text\"].apply(lambda x: re.sub(r'\\s+', ' ', str(x).strip()))\n",
        "tulu_test[\"Text\"] = tulu_test[\"Text\"].str.lower()\n",
        "tulu_test[\"Text\"] = tulu_test[\"Text\"].apply(\n",
        "    lambda x: re.sub(r'\\s+', ' ', ''.join(char for char in str(x) if char not in string.punctuation).strip()).lower()\n",
        ")\n",
        "\n",
        "# Function to clean text\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^\\w\\s,]', '', text)  # Remove emojis and special characters\n",
        "    text = re.sub(r'\\s+', ' ', text).strip()  # Remove extra whitespace\n",
        "    return text\n",
        "\n",
        "tulu_test[\"Text\"] = tulu_test[\"Text\"].apply(clean_text)\n",
        "\n",
        "# Remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "tulu_test[\"Text\"] = tulu_test[\"Text\"].apply(\n",
        "    lambda x: ' '.join(word for word in x.split() if word not in stop_words)\n",
        ")\n",
        "\n",
        "# Lemmatization\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "tulu_test[\"Text\"] = tulu_test[\"Text\"].apply(\n",
        "    lambda x: ' '.join(lemmatizer.lemmatize(word) for word in x.split())\n",
        ")\n",
        "\n",
        "# Expand contractions\n",
        "tulu_test[\"Text\"] = tulu_test[\"Text\"].apply(lambda x: contractions.fix(x))\n",
        "\n",
        "# Remove custom stopwords\n",
        "custom_stopwords = {\"super\", \"vlog\", \"gameplay\"}\n",
        "tulu_test[\"Text\"] = tulu_test[\"Text\"].apply(\n",
        "    lambda x: ' '.join(word for word in x.split() if word not in custom_stopwords)\n",
        ")\n",
        "\n",
        "# Replace negations\n",
        "tulu_test[\"Text\"] = tulu_test[\"Text\"].apply(\n",
        "    lambda x: re.sub(r'\\bnot (\\w+)', r'not_\\1', x)\n",
        ")\n",
        "\n",
        "# Remove repeated characters\n",
        "tulu_test[\"Text\"] = tulu_test[\"Text\"].apply(\n",
        "    lambda x: re.sub(r'(.)\\1+', r'\\1\\1', x)\n",
        ")\n",
        "\n",
        "# Define a new cleaned column without dropping rows\n",
        "tulu_test['cleaned_text'] = tulu_test[\"Text\"].apply(clean_text)\n",
        "\n",
        "# Remove repeating characters in the cleaned text\n",
        "def remove_repeated_chars(text):\n",
        "    return re.sub(r'(.)\\1+', r'\\1', text)\n",
        "\n",
        "tulu_test['cleaned_text'] = tulu_test['cleaned_text'].apply(remove_repeated_chars)\n",
        "\n",
        "# Ensure no rows are dropped\n",
        "print(len(tulu_test))  # Length of the dataframe after processing\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KrmM7yxUUbxe",
        "outputId": "3fcf1077-2859-42d2-9471-9e6452871bb0"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.11/dist-packages (0.1.73)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.11/dist-packages (from contractions) (0.0.24)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (0.3.2)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.11/dist-packages (from textsearch>=0.0.21->contractions) (2.1.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1479\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SVM MODEL"
      ],
      "metadata": {
        "id": "h6p7G3WXUm20"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "vectorizer = TfidfVectorizer(max_features=5000)\n",
        "# Separate features and labels\n",
        "X_train = vectorizer.fit_transform(tulu_train['cleaned_text'])  # Assuming vectorized cleaned text\n",
        "y_train = tulu_train['Label']\n",
        "\n",
        "# Apply SMOTE\n",
        "smote = SMOTE(random_state=42)\n",
        "X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "\n",
        "\n",
        "# Compute class weights\n",
        "class_weights = compute_class_weight('balanced', classes=y_train.unique(), y=y_train)\n",
        "class_weight_dict = dict(zip(y_train.unique(), class_weights))\n",
        "\n",
        "# Train the model with class weights\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "svm_model = SVC(kernel='linear', class_weight=class_weight_dict, random_state=42)\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "# Vectorize the test data\n",
        "X_test = vectorizer.transform(tulu_test['cleaned_text'])\n",
        "#y_test = tulu_train['Label']\n",
        "\n",
        "# Predict on test data\n",
        "y_pred = svm_model.predict(X_test)\n",
        "tulu_test['Label']=y_pred\n",
        "\n",
        "# Check the updated DataFrame\n",
        "tulu_test.drop(columns=['Text'], inplace=True)\n",
        "tulu_test.drop(columns=['cleaned_text'], inplace=True)\n",
        "\n",
        "tulu_test.head()\n",
        "\n",
        "print(tulu_test.head())\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su_E6AFoUjsc",
        "outputId": "64595d3a-373b-4835-cafd-2fae88929c6d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Id     Label\n",
            "0  SA_TU_01  Not Tulu\n",
            "1  SA_TU_02  Not Tulu\n",
            "2  SA_TU_03  Not Tulu\n",
            "3  SA_TU_04   Neutral\n",
            "4  SA_TU_05   Neutral\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tulu_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "to2fr1j5W3OR",
        "outputId": "e9e77e55-2f2a-43df-d07e-b5575734a1a3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              Id     Label\n",
            "0       SA_TU_01  Not Tulu\n",
            "1       SA_TU_02  Not Tulu\n",
            "2       SA_TU_03  Not Tulu\n",
            "3       SA_TU_04   Neutral\n",
            "4       SA_TU_05   Neutral\n",
            "...          ...       ...\n",
            "1474  SA_TU_1475  Negative\n",
            "1475  SA_TU_1476     Mixed\n",
            "1476  SA_TU_1477  Not Tulu\n",
            "1477  SA_TU_1478   Neutral\n",
            "1478  SA_TU_1479   Neutral\n",
            "\n",
            "[1479 rows x 2 columns]\n"
          ]
        }
      ]
    }
  ]
}
